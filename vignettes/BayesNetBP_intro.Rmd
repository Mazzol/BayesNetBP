---
title: "Inference in Bayesian Networks with R package `BayesNetBP`"
author: "Han Yu, Rachael Hageman Blair"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Inference in Bayesian Networks with R package `BayesNetBP`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: vig_bib.bib
---

# Introduction
The `Bayes`ian `Net`work `B`elief `P`ropagation (`BayesNetBP`) package was developed in the R programming language (https://www.r-project.org/), for probabilistic reasoning in Probabilistic Graphical Models (PGMs) known as Bayesian Networks (BNs). Implementation of the belief propagation is based on the work by @cowell2005local. If you would like to use `BayesNetBP` in your publications, please cite the package as

>Han Yu, Moharil Janhavi, Rachael Hageman Blair. "BayesNetBP: An R package for probabilistic reasoning in Bayesian Networks". \textit{Submitted}.

Bayesian networks are a class of PGMs that convey directed dependencies between variables (nodes) in the network.  These dependencies can be read from the graph as conditional probabilities and are factored terms in a compact representation of the joint probability distribution for the variables in the network @lauritzen1996graphical, @koller2009probabilistic.  A BN is a Directed Acyclic Graph (DAG), which ensures there is no feedback in the network, and is required for the factorization of the joint distribution.  A BN for a set of random variables, $D=\{X_1,X_2, \ldots X_n\}$, obeys the \emph{Markov condition}, which states that each variable, $X_i$, is independent of its ancestors, given its parents in the graphs, $G$.  Under these assumptions, the structure of a BN encodes conditional independence relationships: 
\begin{equation}
P\left(X_1,X_2,\ldots, X_n\right) = P(G)\prod_{i=1}^{n} P\left(X_i \mid {\rm{pa}}(X_i) , \Theta_i \right), \label{eq:bn}
\end{equation}  
where  $P(G)$ is the prior distribution over the graph $G$, ${\rm{pa}}(X_i)$ are the parent nodes of child $X_i$, and $\Theta_i$ denotes the parameters of the local probability distribution.

The BN described in Equation \ref{eq:bn} can be constructed directly from the relationships depicted in the DAG (Directed Acyclic Graph).  Specifically, the building blocks convey the conditional probability of a child node given its parents, $P\left(X_i \mid {\rm{pa}}(X_i) , \Theta_i \right)$.  This parent-child relationship is often referred to as a \emph{local model}.  For purely continuous or purely discrete BNs, these local model are often defined using Gaussian regressions and Conditional Probability Table (CPTs), respectively.  However, additional modeling assumptions are necessary in the network and local models when there is a mixture of discrete and continuous nodes.

Conditional Gaussian Bayesian Networks (CG-BNs) accommodate a mixture of discrete and continuous variables. Following @lauritzen1996graphical, @lauritzen2001stable, we denote the set of discrete nodes as, $\Delta$, and the set of continuous nodes as $\Gamma$.  For a continuous variable $Y=X_j \in \Gamma$, we define a local model as a conditional Gaussian regression on states of the discrete parents $I$ of $Y$: 
\[L\left(Y\mid I=i, Z=z\right) = N\left(\alpha(i)+\beta (i)^{T}z, \sigma^2(i) \right),\]
where $\alpha(i)$ is the mean of the regression, $\beta$ denotes the regression coefficients, $Z\in\Gamma$ are the the continuous parents of $Y$, and the variance, $\sigma^2(i)$ depends only on the discrete states of the parents.  Importantly, in a CG-BN, discrete nodes can be parents of continuous nodes, but not vice-versa.  

The package `BayesNetBP` can be seamlessly connected with other tools in R for graphical modeling for the purpose of belief propagation and visualization.  The input to `BayesNetBP` is a DAG.  The package is flexible in that it can accommodate DAGs learned from different packages in R such as `bnlearn`, `RHugin`, `qtlnet` or a network that is described by an \emph{expert} based on prior knowledge network structure.  `BayesNetBP` accommodates networks that are continuous, discrete or a mixture of discrete and continuous variables.  However, mixed networks must be structured such that the CG-BN properties regarding discrete nodes preceding continuous nodes, is satisfied.

There are two packages developed in the R programming language that can be used for belief propagation, `RHugin` and `gRain`. `RHugin` can be used for network inference and belief propagation for CG-BNs, but relies on the commercial software Hugin. While a free demo version of huginlite can be used in connection with `RHugin`, the reasoning and inference is limited to smaller networks and datasets (50 states and 500 cases) for the demo version. The `gRain` package can handle large datasets and networks, but it supports probabilistic reasoning only in purely discrete networks.  On the other hand, `BayesNetBP`, not only supports probabilistic reasoning in purely discrete, purely continuous, and CG-BNs, but also provides tools for quantification of distributional changes and visualization. Therefore, the `BayesNetBP` package fills a major gap in the graphical modeling tools available in R. The package is the first open source package to facilitate probabilistic reasoning and novel visualizations in all types of BNs.  In the following sections, we present examples that are motivated by problems in statistical genetics.  However, we emphasize that the `BayesNetBP` can be used in connection with any application.

# CG-BN example
The data is from the livers from a MRL/MpJ x SM/J mouse intercross, and consists of gene expression data, genotypes at SNP markers and High Density Lipoprotein (HDL) @leduc2012using.  Genes that share a QTL with HDL on chromosome 1 and also relate to enriched categories for lipid metabolism in KEGG and Gene Ontologies were selected @alvord2007david.  The filtered data used for the modeling can be found in the `BayesNetBP` package. Within this network, we also consider dichotomizing three of the nodes, which creates a second discrete layer in the CG-BN. This example demonstrates the functions for initialization, reasoning and visualizations in a CG-BN.

## Model initialization

For initialization, a graphNEL object of DAG and a vector specifying node types are required to build the semi-elimination tree. In this example, the vector `node.class` indicates which nodes are discrete (TRUE) and continuous (FALSE).  The `ClusterTreeCompile` function builds the graph of semi-elimination tree and get the cluster sets, which are the frame work of the final computational object. The `LocalModelCompile` function estimates the local models from a DAG and a data frame. The columns of the data frame must be named by corresponding node names. The local models computed by `LocalModelCompile` function are distributed into the semi-elimination tree through the `ElimTreeInitialize` function. After initialization, a `ClusterTree` object will be generated.

```{r, fig.show='hold', cache=TRUE}
library(BayesNetBP)
data(liver)
liver$node.class
# Build cluster tree
cst <- ClusterTreeCompile(dag=liver$dag, node.class = liver$node.class)
# Obtain local models
models <- LocalModelCompile(data=liver$data, dag=liver$dag, node.class=liver$node.class)
# Initialize
tree.init <- ElimTreeInitialize(tree=cst$tree.graph, dag=cst$dag, model=models, 
                                node.sets=cst$cluster.sets, node.class=cst$node.class)
# Propagate discrete compartment
tree.init.p <- PropagateDBN(tree.init)
```

The `ClusterTree` object is not ready for evidence absorption or making queries untill its discrete compartment is propagated. The function `PropagateDBN` will perform the propagation within the discrete compartment of the clustertree object so that the joint distribution tables of all clusters are computed.  Now the object is ready for evidence absorption and queries.

```{r, fig.show='hold', cache=TRUE}
tree.init@propagated
tree.init.p <- PropagateDBN(tree.init)
tree.init.p@propagated
```

## Entering evidence and making queries

The `GetValue` function can be used to check how the values for each discrete variable are coded. For example, the following code shows the locus Chr1\@42.65 has three states, while Spgl1 has two states "High" and "Low". This information is helpful for evidence absorption.

```{r, fig.show='hold', cache=TRUE}
GetValue(tree.init.p, "Nr1i3")
GetValue(tree.init.p, "chr1_42.65")
GetValue(tree.init.p, "Spgl1")
```

The `AbsorbEvidence` function can handle evidence of a numeric value for continuous nodes. For a discrete node, the evidence can be either an observed state (hard evidence) or a likelihood (soft evidence). In the following example, these three kinds of evidence: Nrli3 is observed with 1, Chr1\@42.65 is observed with state 1, and the likelihood of Spgl1 being High is 0.9, and being Low is 0.2. There three pieces of information can enter the model simultaneously throught the `AbsorbEvidence` function. The absorbed information in the model can also be accessed. 

```{r, fig.show='hold', cache=TRUE}
tree.post <- AbsorbEvidence(tree.init.p, c("Nr1i3", "chr1_42.65", "Spgl1"), 
                            list(1, "1", c(High=0.9, Low=0.2)))
tree.post@absorbed.variables
tree.post@absorbed.values
tree.post@absorbed.soft.variables
tree.post@absorbed.soft.values
```

The marginal distributions of both continuous and discrete variables can be queried with the function `Marginals`.  For a continuous variable, the marginal is a mixture of Gaussian distributions, output as a data frame with three columns of sub-population probabilities, means and variances. For a discrete variable, the marginal is a named vector of probabilities. The function `SummaryMarginals` computes means and standard deviations for continuous variables as well as returns the number of sub-populations. In the following example, the marginals of both Ppap2a and Neu1 comprise of 108 Gaussian sub-populations. 

```{r, fig.show='hold', cache=TRUE}
marg <- Marginals(tree.post, c("HDL", "Ppap2a", "Neu1", "chr1_71.35"))
marg$marginals$HDL
SummaryMarginals(marg)
head(marg$marginals$Ppap2a)
```

`BayesNetBP` can be used to visualize marginal distributions of both discrete and continuous nodes with the `PlotMarginals` function. The function outputs multiple marginal distributions simultaneously. Marginals of continuous nodes are shown as density plots, while those of discrete nodes as barplots. 

```{r, fig.show='hold', fig.height = 3.5, fig.width = 6, fig.align = "center", cache=TRUE}
PlotMarginals(marg)
```

The following codes compare the marginal distributions of Neu1 before and after absorbing the above evidence.

```{r, fig.show='hold', cache=TRUE, fig.height = 4, fig.width = 4, fig.align = "center"}
var <- "Neu1"
marg.2 <- Marginals(tree.post, var)
marg.1 <- Marginals(tree.init.p, var)
mgns <- list(marg.1$marginals[[1]], marg.2$marginals[[1]])
names(mgns) <- c(var, var)
types <- c(marg.1$types[1], marg.2$types[1])
marg <- list(marginals=mgns, types=types)
PlotMarginals(marg, groups=c("before", "after"))
```

The function `FactorQuery` can provide the joint distribution of any combination of factors, as well as conditional distributions of all discrete variables.  In the following example, the joint distrbution of HDL and Cyp2b10, and the conditional distribution of HDL, are computed. For now, only conditional distributions of single nodes can be queried. The output is the distribution of the queried node conditional on all its parents.

```{r, fig.show='hold', cache=TRUE}
# query joint distribution for HDL and Cyp2b10
FactorQuery(tree.post, c("HDL", "Cyp2b10"), mode="joint")
# query joint or conditional distributions for HDL
FactorQuery(tree.post, c("HDL"), mode="conditional")
```

## Visualization

The shift of marginals between two models can also be visualized using `PlotCGBN` function. This function takes input of two `ClusterTree` objects, computes the signed and symmetric KL divergence between marginals for each variable, and outputs a graph whose nodes are colored accordingly.  Figure 5 shows an example in which Nr1i3 and Chr1\@42.65 have absorbed hard evidence (green).  The changes of the marginals for the other nodes are quantified using a signed and symmetric KL divergence.  They are depicted on the network with a colorbar representaion.  Note that the discrete nodes will only change in one direction.  For the continuous nodes, red indicates an increase in mean (activation), and blue a decrease in mean (inhibited).  This function also returns the signed symmetric KL divergence for each node. 

```{r, fig.show='hold', fig.height = 4, fig.width = 5, fig.align = "center", cache=TRUE}
PlotCGBN(tree.init.p, tree.post, fontsize = 32)
```

In the following example, the `PlotCGBN` function is used to demonstrate how conditional independencies within the network change based upon where evidence has been oberved.  The Bayesian network in Figure 5 has an active trail between Spgl1 and Chr1\@84.93, so after observing Spgl1, the marginal of chr1@84.93 will change (symmetric KL divergence is 0.0047).  However, if Cyp2b10 is also observed (gray), then Spgl1 and Chr1\@84.93 become \emph{d}-separated, and further absorption of evidence on Spgl1 will not change the distribution of Cypb10 (symmetric KL divergence is 0).  The exploration of the conditional independencies described can be performed by simply absorbing Cyp2b10 into the orginal model to get `tree.1`, and further absorb Spgl1 into it to get `tree.2`, and finally compare `tree.1` and `tree.2` by `PlotCGBN`.  

```{r, fig.show='hold', fig.height = 4, fig.width = 5, fig.align = "center", cache=TRUE}
tree.1 <- AbsorbEvidence(tree.init.p, c("Cyp2b10"), list("High"))
tree.2 <- AbsorbEvidence(tree.1, c("Spgl1"), list("High"))
tree.3 <- AbsorbEvidence(tree.init.p, c("Spgl1"), list("High"))
PlotCGBN(tree.1, tree.2, fontsize = 32)
PlotCGBN(tree.init.p, tree.3, fontsize = 32)
```

```{r, fig.show='hold', cache=TRUE, fig.height = 4, fig.width = 5, fig.align = "center"}
library(reshape2)
library(ggplot2)
klds <- ComputeKLDs(tree=tree.init.p, var0="Nr1i3", 
                    vars=setdiff(tree.init.p@node, "Nr1i3"), 
                    seq=seq(-3,3,0.2), pbar=FALSE)
klds.melt <- melt(klds, id="x")
ggplot(data=klds.melt, aes(x=x, y=value, group=variable, colour=variable)) +
  geom_line() +
  ylab("Divergence") +
  xlab("Nr1i3") +
  theme_bw() +
  theme(legend.key = element_blank())
```

# Discrete BN example
In this example, we examine a completely dicrete network.  The yeast dataset is a subset of the widely studied yeast expression dataset comprising of 112 F1 segregants from a cross between BY4716 and RM11-1a strains of Saccharomyces Cerevisiae @brem2005landscape.  The original dataset consists of expression values reported as log2(sample/reference) for 6,216 genes. The full data can be accessed in Gene Expression Omnibus (GEO) - accession number GSE1990 @barrett2013ncbi.  The subset of genes was identified after filtering, linkage analysis and model building.  Briefly, 901 expression values mapped to the YeastNet database @kim2013yeastnet.  Linkage analysis was performed on these traits using R/qtl @qtlbook.  369 genes that had a significant QTL were used as predictors in an elastic net regression model with COX10 as the response variable @zou2005regularization.  The optimal shrinkage parameter was identified as 0.086 using a 10-fold cross validation scheme.  The resulting model shrunk all but 37 regression coefficients to zero. The 38 genes including COX10 and their 12 SNP markers corresponding to their QTL were included as variables for the graphical model.  This set of 38 genes and their corresponding 12 SNP markers were identified and included in the yeast dataset.  

In order to derive discrete nodes for network analysis, the gene expression values were dichotemized at the median.  The discrete variables are binary genotype states that indicate the parental strain of origin.  To demonstrate compatibility with existing packages, as a starting point, the structure of the BN is learned using a hill-climbing method in the `bnlearn` package.  The modeling assumptions that require genotypes to be upstream of phenotype can be directly encoded using the `blacklist` option. 

```{r, fig.show='hold', message=FALSE, warning=FALSE, cache=TRUE}
library(bnlearn)
library(igraph)
# learning the network structure
data(yeast)
node.names <- names(yeast)
geno <- node.names[1:12]
pheno <- node.names[13:50]

# get the blacklist
bl <- rbind(expand.grid(geno, geno), expand.grid(pheno, geno))
names(bl) <- c("from", "to")

# fit network
fit <- bnlearn::hc(yeast, blacklist = bl)
dag <- as.graphNEL(fit)
dag.graph <- igraph.from.graphNEL(dag)

# remove isolated nodes
deg <- igraph::degree(dag.graph)
nodes <- names(deg)[deg>0] 
dag.graph <- induced_subgraph(dag.graph, nodes)
dag <- igraph.to.graphNEL(dag.graph)
```

After the network structure being learnt, the models and cluster tree can be built in the same procedure as a CG-BN. `BayesNetBP` brings networks with purely discrete, continuous, or mixed (both discrete and continuous) types of nodes under the same framework, so they can be analyzed conveniently using the identical procedure  The following figure shows the structure of constructed semi-elimination tree, which is plotted using the `PlotTree` function. The nodes in the cluster tree plot are named by their corresponding elimination nodes.

```{r, fig.show='hold', cache=TRUE, fig.height = 5, fig.width = 5, fig.align = "center"}
node.class <- rep(TRUE, length(nodes))
names(node.class) <- nodes
cst <- ClusterTreeCompile(dag=dag, node.class=node.class)
models <- LocalModelCompile(data=yeast, dag=dag, node.class=node.class)
tree.init <- ElimTreeInitialize(tree=cst$tree.graph, dag=cst$dag, model=models, 
                                node.sets=cst$cluster.sets, node.class=cst$node.class)
tree.init.p <- PropagateDBN(tree.init)
PlotTree(tree.init.p)
```

Evidence absorption and marginal computation can be performed in the exactly same manner as in the CG-BN example. The marginals can be visualized using `PlotMarginals`. 

```{r, fig.show='hold', cache=TRUE, fig.height = 3, fig.width = 5, fig.align = "center"}
tree.post <- AbsorbEvidence(tree.init.p, c("MSY1", "Qchr4"), list("1", "2"))
marg.yeast <- Marginals(tree.post, nodes[2:5])
PlotMarginals(marg.yeast)
```

The `PlotCGBN` function can still be used to compare the marginals from two models.

```{r, fig.show='hold', cache=TRUE, fig.height = 5, fig.width = 5, fig.align = "center"}
div <- PlotCGBN(tree.init.p, tree.post, fontsize = 24)
```

Queries on joint and conditional distributions of factors is also straightforward and can be output in tabular form. 

```{r, fig.show='hold', cache=TRUE}
FactorQuery(tree.post, nodes[2:5], mode="joint")
FactorQuery(tree.post, "ERG9", mode="conditional")
```

# Continuous BN example
In this section, we showcase an application of `BayesNetBP` package on purely continuous network without showing the code. The network is constructed based on the 100 genes with highest variances from the NCI60 data set with the `gRapHD` package @de2009high. A DAG is induced from the resulted undirected acyclic graph. The following figure visualizes the difference in marginals for models before and after observing $V5=2$. The initialization, reasoning and visualization in this setting follows identical steps as previous two examples.

\begin{figure}
\begin{center}
\includegraphics[width=6in]{C:/Users/Han/Desktop/cont_ex.pdf}
\end{center}
\end{figure}

# BayesNetBP Shiny App
The function `runBayesNetApp` lauches the Shiny App accompanied with this package. The app loads the `toytree` example by default and allows users to load customized `ClusterTree` object. In order to use this feature, a `ClusterTree` object should be built, propagated and named `tree.init.p`, and then saved as a `.RDATA` file. This file can be read in by the app. 

The console of `BayesNetBP` Shiny App comprises of three panels. The first part controls the model loading and network layouts. It also allows user to subset the network to faciliate visualization. The `Expand` function can trace the ancestors, descendants, or both, of a selected node in a stepwise manner. The expanded nodes will be colored orange. By clicking `Add to list`, the expanded nodes will be selected and shown purple. The user can then continue selecting additional nodes by using `Expand` and `Add to list` functions. After selecting desired node sets, the user can subset the graph by clicking `Subset`. The nodes in subsetted graph retain all properties before subsetting, including their colors and divergence. Other operations can also be performed on the reduced network.

The second panel is used for absorption of fixed and hard evidences. The users can add multiple pieces of evidence to a list and absorb them into the model simultaneously. The nodes with evidence absorbed will be colored green when the absorption is complete. Marginals of the nodes can be quried as density or bar plots by node types. If a set of evidence has been absorbed, the marginals both before and after absorption will be returned to facilitate comparison. To query the marginals, the user can select the node of interest in the graph, and then click `Plot Marginals`. The `Shift in Marginals` function computes the signed and symmetric Kullback-Liebler divergence for all applicable nodes in the network, and colors the nodes in a similar manner as the function `PlotCGBN`. 

The function for systematic assessment of variable marginal shifts is provided in the third panel. It allows user to specify which node to absorb the spectrum of evidence in a menu, and to select whose divergence to be calculated by firstly selecting the node on the graph and then clicking `Add to Plot List`. Alternatively, the user can use Add All function to select all applicable nodes into the plotting list. The result is visualized in an interactive plot.

\begin{figure}
\begin{center}
\includegraphics[width=6in]{C:/Users/Han/Desktop/shiny.pdf}
\end{center}
\caption{The console of `BayesNetBP` Shiny App.}
\end{figure}

# References
